---
title: "Journal and community profiles"
author: "David Selby"
date: "`r format(Sys.Date(), '%e %B %Y')`"
output:
  rmarkdown::html_vignette:
    df_print: kable
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

Suppose we have a citation matrix \(\mathbf{X}\), where \(x_{ij}\) is the number of citations from journal \(j\) to journal \(i\).
Then the *citation profile* of journal \(j\) is the proportion of its references assigned to each of the other journals, given as the vector \(\mathbf{p}_j\), for \((\mathbf{p}_{j})_{i} = \frac{x_{ij}}{\sum_i x_{ij}}\).

For example, if \(\mathbf{X}\) were the following citation matrix,
```{r, echo = 2:3}
library(Matrix)
library(scrooge)
X <- citations[1:6, 1:6]
diag(X) <- 0
as.data.frame.matrix(X)
```
then the citation profiles, arranged side-by-side as a matrix \(\mathbf{P}\), would be
```{r, echo = 1}
P <- cprofile(X)
round(as.data.frame.matrix(P), 2)
```
Every column sums to one.
```{r}
colSums(P)
```

Suppose that our journals have been arranged into clusters, perhaps by a domain expert or as the output of a community detection algorithm.

The following clustering puts *Annals of the Institute of Statistical Mathematics* (AIMS), *Australian and New Zealand Journal of Statistics* (ANZS) and *Bernoulli* (Bern) together in one group, whilst *Annals of Statistics* (AoS), *American Statistician* (AmS) and *Biometrical Journal* (BioJ) each form singleton groups.
```{r}
comm <- c(AmS  = 1,
          AIMS = 2,
          AoS  = 3,
          ANZS = 2,
          Bern = 2,
          BioJ = 4)
```

The *community profiles* are the average of their members' journal profiles.
In the case of communities with just one member, the community profile is the same as that journal's profile.
```{r, echo = 1}
C <- community_profile(X, comm)
round(as.data.frame.matrix(C), 2)
```
Because groups 1, 3 and 4 are singletons, their profiles are equal to the journal profiles of AmS, AoS and BioJ, respectively.
Group 2's profile is equal to the average of its member profiles, though this definition may change.

## Quadratic programming

The package `quadprog` is designed to solve quadratic programming problems of the form
\[\min\,\Bigl\{ -\mathbf{d}^\text{T} \mathbf{b} + \frac12 \mathbf{b}^\text{T} \mathbf{D} \mathbf{d} \Bigr\}\]
subject to the constraints
\[\mathbf{A}^\text{T} \mathbf{b} \geq \mathbf{b}_0.\]

We have the following scenario.
We want to minimise the Euclidean distance between \(\mathbf{b}\), an unknown point somewhere in the convex hull of the community profiles,
and \(\mathbf{p}\), a (given) journal profile that may be outside the convex hull, but somewhere within the \(k-1\) simplex, where \(k\) is the total number of journals.

```{r diagram, fig.width = 7, fig.height = 5, dev.args = list(type = 'cairo'), echo = FALSE}
library(grid)
grid.newpage()

# C
x <- c(.5, .9, .6)
y <- c(.1, .3, .9)
grid.text(expression(c[1]), x[1]-.025, y[1])
grid.text(expression(c[2]), x[2]+.025, y[2])
grid.text(expression(c[3]), x[3]-.025, y[3])

# convex hull
grid.polygon(x, y,
             gp = gpar(col = '#dddddd', fill = '#efefef'))
grid.points(x, y, pch = 19,
            gp = gpar(col = 'steelblue'),
            default.units = 'npc')
grid.text('convex hull', .68, .4,
          gp = gpar(col = '#cccccc', fontface = 'italic'))



# p <--> b
grid.segments(.3, .55, .55, .5,
              gp = gpar(col = '#bbbbbb', lty = 2))

# p
grid.points(.3, .55, pch = 19,
            gp = gpar(col = 'tomato2'),
            default.units = 'npc')
grid.text('p', .28, .55, gp = gpar(fontface = 'bold', just = 'top'))

# b
grid.points(.55, .5, pch = 19,
            gp = gpar(col = 'seagreen'),
            default.units = 'npc')
grid.text('b', .57, .5, gp = gpar(fontface = 'bold', just = 'top'))
```

Because our point lies in the convex hull of the community profiles, finding the vector \(\mathbf{b}\) is equivalent to finding a vector of weights \(\mathbf{w} \geq \mathbf{0}\) such that \(\mathbf{Cw} = \mathbf{b}\) and \(\sum w_i = 1\), where \(\mathbf{C} = \begin{pmatrix}\mathbf{c}_1 & \mathbf{c}_2 & \dots & \mathbf{c}_g\end{pmatrix}\), the matrix of \(g\) community profiles.

Hence the quadratic programme is
\[
\min Q = \|\mathbf{p} - \mathbf{b}\|
= \|\mathbf{p} - \mathbf{Cw}\|
= \mathbf{p}^\text{T} \mathbf{p}
  + \mathbf{w}^\text{T} \mathbf{C}^\text{T}\mathbf{Cw} - 2 \mathbf{p}^\text{T} \mathbf{Cw},
\]
subject to
\[\begin{aligned}
\mathbf{1}^\text{T} \mathbf{w} &= 1, \\
\mathbf{w} &\geq \mathbf{0}.
\end{aligned}\]

Minimising \(Q\) is equivalent to minimising
\[Q_2 = \frac12 \mathbf{w} \mathbf{C}^\text{T} \mathbf{Cw} - \mathbf{p}^\text{T} \mathbf{Cw},\]
because \(\mathbf{p}\) is fixed and the factor of \(\frac12\) does not depend on \(\mathbf{b}\).
This is in the standard quadratic programming syntax from above.
The constraints are
\[\begin{pmatrix}
  \mathbf{1}^\text{T} \\
  \mathbb{I}_g
\end{pmatrix}
\mathbf{w}
\mathrel{
  \begin{array}
    {}= \\
    \geq
  \end{array}
}
\begin{pmatrix}
1 \\ \mathbf{0}
\end{pmatrix}
\]

The function `nearest_point` solves this quadratic programme and returns the optimal solution and its distance.

(The optimiser actually computes \(Q_2\), then returns \(Q = Q_2 + \frac12 \mathbf{p}^\text{T}\mathbf{p}\) so that it may be interpreted correctly in the context of distance from the convex hull of community profiles.)

## Demonstration

What convex combination of community profiles best represents the journal *Annals of Statistics*?
```{r, echo = 1}
AoS_dist <- nearest_point('AoS', X, comm)
AoS_dist
```
From the output, the combination vector is \(\begin{pmatrix}`r paste(round(AoS_dist$sol, 2), collapse = '&')`\end{pmatrix}\), and AoS's journal profile has distance `r AoS_dist$value` from the convex hull.
This should be intuitive---as a singleton community, AoS's journal profile *is* a community profile.

What about another journal, say *Bernoulli* or ANZS?
```{r, echo = 1}
Bern_dist <- nearest_point('Bern', X, comm)
Bern_dist
```
The combination vector for *Bernoulli* is \(\begin{pmatrix}`r paste(round(Bern_dist$sol, 2), collapse = '&')`\end{pmatrix}\), which is `r round(sqrt(Bern_dist$value), 2)` units away from the convex community hull.

```{r, echo = FALSE}
ANZS_dist <- nearest_point('ANZS', X, comm)
```

ANZS has combination vector \(\begin{pmatrix}`r paste(round(ANZS_dist$sol, 2), collapse = '&')`\end{pmatrix}\), and is `r round(sqrt(ANZS_dist$value), 2)` units away from the convex community hull.

Notice how although *Bernoulli* and ANZS are both members of community 2, it looks like *Bernoulli*---if citation profile were to be used as a measure of community similarity---might actually be a better fit for community 4, along with *Biometrical Journal*.
Recall these journals' profiles and you see they are quite similar.
```{r echo = F}
round(as.data.frame.matrix(P[, c('Bern', 'BioJ')]), 2)
```

## Practical example

Consider the `scrooge` package's built-in `citations` data set.
This was collected by Varin et al. (2016) for their paper [Statistical modelling of citation exchange between statistics journals](http://doi.org/doi:10.1111/rssa.12124), published in *JRSS-A*.
It includes the citation counts between 47 statistics journals.

```{r}
dim(citations)
```

What communities might lie in this dataset?
The original paper suggested hierarchical clustering of Pearson distances between symmetrised citation counts, yielding eight clusters including two singletons.
We can recreate that result here.
```{r, results = 'asis', echo = 1:3}
pearson_distances <- as.dist(1 - cor(citations + t(citations), method = 'pearson'))
dendrogram <- hclust(pearson_distances, method = 'complete')
clustering <- cutree(dendrogram, h = 0.8)

# Print an enumerated list of the clusters.
cat(
  paste(c('',
        sapply(split(names(clustering), clustering),
               function(li) paste(li, collapse = ', ')
               )
        ),
      collapse = '\n1. ')
  )
```

We can compute these eight clusters' community profiles.

```{r, echo = 1, fig.width = 5, fig.height = 8, message = FALSE, fig.align = 'center'}
profiles47 <- community_profile(citations, clustering)

library(dplyr)
library(ggplot2)
theme_set(theme_minimal())

profiles47 %>%
  Matrix::summary() %>%
  ggplot(aes(x = as.factor(j),
             y = rownames(profiles47)[i],
             fill = x)) +
    geom_tile() +
    viridis::scale_fill_viridis('P', direction = -1) +
    scale_x_discrete('community', position = 'bottom') +
    ylab(NULL)
```

Hence we compute Euclidean distances from every journal profile to the convex hull of the community profiles.

```{r, echo = 1, fig.height = 8, fig.width = 5, fig.align = 'center'}
hull_distances <- vapply(rownames(citations),
                         function(j)
                           nearest_point(j, citations, clustering)$value,
                         FUN.VALUE = numeric(1))

data_frame(journal = names(hull_distances),
           distance = hull_distances) %>%
  ggplot(aes(sqrt(pmax(0, distance)),
             reorder(journal, distance))) +
    scale_y_discrete(NULL, labels = NULL) +
    scale_x_continuous('distance from convex hull',
                       expand = c(0.1, 0)) +
    geom_text(aes(label = journal))
```

Naturally, the singletons *Stata Journal* and *Journal of Statistical Software* have distance zero to the communities hull, because they are themselves communities.
The relative distances of the other journals might be interpreted as a measure of how well they are described by the clustering structure.
Higher distances imply journals less well-represented by community profiles.

The sum of squared distances is **`r signif(sum(hull_distances), 4)`** units^2^.
On its own, this doesn't really tell us much about the quality of our clustering.

For comparison, we can try a couple of other clustering algorithms.
The Infomap algorithm ([Rosvall & Bergstrom 2008](http://doi.org/doi:10.1073/pnas.0706851105)) is implemented in the R package `igraph`.

```{r, results = 'asis', echo = 2:4, message = FALSE}
set.seed(2017)
library(igraph)
citations_graph <- graph_from_adjacency_matrix(citations, mode = 'plus')
infomap <- cluster_infomap(citations_graph, nb.trials = 1000)

cat(
  paste(c('',
        sapply(split(infomap$names, infomap$membership),
               function(li) paste(li, collapse = ', ')
               )
        ),
      collapse = '\n1. ')
  )
```

How does the resulting clustering compare with our hierarchical structure from earlier?

```{r, echo = 1, fig.width = 5, fig.height = 8, fig.align = 'center'}
infomap_distances <- vapply(rownames(citations),
                            function(j)
                            nearest_point(j, citations, infomap)$value,
                            FUN.VALUE = numeric(1))

data_frame(journal = names(infomap_distances),
           distance = infomap_distances) %>%
  ggplot(aes(sqrt(pmax(0, distance)),
             reorder(journal, distance))) +
    scale_y_discrete(NULL, labels = NULL) +
    scale_x_continuous('distance from convex hull',
                       expand = c(0.1, 0)) +
    geom_text(aes(label = journal))
```

The sum of squared distances is **`r signif(sum(infomap_distances), 4)`** units^2^, this time.
However, the Infomap algorithm is nondeterministic and occasionally unstable, so you might obtain a different clustering and distance score every time you run it!

Try now the Louvain algorithm ([Blondel et al. 2008](http://doi.org/10.1088/1742-5468/2008/10/P10008)).

```{r echo = 1, results = 'asis'}
louvain <- cluster_louvain(citations_graph)

cat(
  paste(c('',
        sapply(split(louvain$names, louvain$membership),
               function(li) paste(li, collapse = ', ')
               )
        ),
      collapse = '\n1. ')
  )
```

We get the following results.

```{r, echo = 1, fig.width = 5, fig.height = 8, fig.align = 'center'}
louvain_distances <- vapply(rownames(citations),
                            function(j)
                            nearest_point(j, citations, louvain)$value,
                            FUN.VALUE = numeric(1))

data_frame(journal = names(louvain_distances),
           distance = louvain_distances) %>%
  ggplot(aes(sqrt(pmax(0, distance)),
             reorder(journal, distance))) +
    scale_y_discrete(NULL, labels = NULL) +
    scale_x_continuous('distance from convex hull',
                       expand = c(0.1, 0)) +
    geom_text(aes(label = journal))
```

The sum of squared distances is **`r signif(sum(louvain_distances), 4)`** units^2^.
